{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2ba0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "audio_file_path=r'C:\\Mtech1styr\\Speeker Recognition(dataset)\\UrbanSound8K\\audio\\fold1\\7061-6-0-0.wav'\n",
    "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c62531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0231203e-05 2.3116412e-05\n",
      " 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166279b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2238d94b2e0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Lets plot the librosa audio data\n",
    "import matplotlib.pyplot as plt\n",
    "# Original audio with 1 channel \n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c138d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 173)\n"
     ]
    }
   ],
   "source": [
    "mfccs = librosa.feature.mfcc(y=librosa_audio_data, sr=librosa_sample_rate, n_mfcc=40)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99bb8c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-236.01546   , -223.33238   , -230.81067   , ..., -232.38414   ,\n",
       "        -229.38951   , -224.5962    ],\n",
       "       [ 150.09904   ,  164.82231   ,  176.60326   , ...,  196.70139   ,\n",
       "         190.409     ,  162.91656   ],\n",
       "       [   4.2535515 ,  -11.223283  ,  -28.130497  , ...,  -24.908518  ,\n",
       "         -23.637192  ,   -4.0557647 ],\n",
       "       ...,\n",
       "       [  -0.43494892,   -1.9926164 ,   -6.212633  , ...,   -4.0844183 ,\n",
       "          -2.935854  ,   -5.927884  ],\n",
       "       [  -1.6773992 ,    2.6210585 ,    7.741791  , ...,   -9.845162  ,\n",
       "          -9.999222  ,   -5.2083163 ],\n",
       "       [   2.4558196 ,    1.8101326 ,   -0.4259416 , ...,   -2.7711093 ,\n",
       "          -5.384906  ,   -2.728547  ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd133f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Extracting MFCC's For every audio file\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "audio_dataset_path=r'C:\\Mtech1styr\\Speeker Recognition(dataset)\\UrbanSound8K\\audio'\n",
    "metadata=pd.read_csv(r'C:\\Mtech1styr\\Speeker Recognition(dataset)\\UrbanSound8K\\metadata\\UrbanSound8K.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b36d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5844886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3555it [05:09, 10.97it/s]C:\\Anaconda\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  return f(*args, **kwargs)\n",
      "8325it [12:41, 11.84it/s]C:\\Anaconda\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Anaconda\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  return f(*args, **kwargs)\n",
      "8732it [13:30, 10.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e68adc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-218.18938, 71.38549, -131.49442, -52.25892, ...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-425.05234, 110.67095, -54.192833, 62.045406,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-459.82623, 122.82864, -47.908062, 53.302677,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-414.82184, 102.94826, -36.656853, 54.170742,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-447.60776, 115.08627, -53.74607, 61.55309, 1...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature             class\n",
       "0  [-218.18938, 71.38549, -131.49442, -52.25892, ...          dog_bark\n",
       "1  [-425.05234, 110.67095, -54.192833, 62.045406,...  children_playing\n",
       "2  [-459.82623, 122.82864, -47.908062, 53.302677,...  children_playing\n",
       "3  [-414.82184, 102.94826, -36.656853, 54.170742,...  children_playing\n",
       "4  [-447.60776, 115.08627, -53.74607, 61.55309, 1...  children_playing"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc76e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce87d122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c28f235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dog_bark', 'children_playing', 'children_playing', ...,\n",
       "       'car_horn', 'car_horn', 'car_horn'], dtype='<U16')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74659940",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoding\n",
    "y=np.array(pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42bb6baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6465d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1c8ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3211458e+02,  1.1391494e+02, -2.3927406e+01, ...,\n",
       "         3.3260243e+00, -1.4790288e+00,  2.8912868e+00],\n",
       "       [-1.4296137e+01,  9.1951004e+01, -8.6025953e+00, ...,\n",
       "        -3.3708370e+00, -5.2008629e+00, -1.5975088e+00],\n",
       "       [-4.9827820e+01,  1.8449357e-01, -2.0364500e+01, ...,\n",
       "         2.0259936e+00, -8.3159238e-01,  2.7930877e+00],\n",
       "       ...,\n",
       "       [-4.2723694e+02,  9.2938095e+01,  2.8287885e+00, ...,\n",
       "         8.1411344e-01,  6.6066748e-01,  7.8365982e-01],\n",
       "       [-1.4640692e+02,  1.3716916e+02, -3.4362492e+01, ...,\n",
       "         1.3839475e+00, -1.9667517e+00, -8.8792086e-01],\n",
       "       [-4.2171307e+02,  2.1160454e+02,  2.5852380e+00, ...,\n",
       "        -5.1338639e+00, -3.6135261e+00, -1.3413876e+00]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2db7e62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "867798d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6985, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbecd283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 40)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45ee00e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6985, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7fc1c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eba76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09519618",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "487f9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b031f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,410\n",
      "Trainable params: 45,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51d6a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13fa4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 10.3777 - accuracy: 0.1212\n",
      "Epoch 00001: val_loss improved from inf to 2.27553, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 3s 4ms/step - loss: 9.9147 - accuracy: 0.1201 - val_loss: 2.2755 - val_accuracy: 0.1351\n",
      "Epoch 2/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 2.5225 - accuracy: 0.1408\n",
      "Epoch 00002: val_loss improved from 2.27553 to 2.26878, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 2.5139 - accuracy: 0.1409 - val_loss: 2.2688 - val_accuracy: 0.1276\n",
      "Epoch 3/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 2.3097 - accuracy: 0.1519\n",
      "Epoch 00003: val_loss improved from 2.26878 to 2.20183, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3097 - accuracy: 0.1518 - val_loss: 2.2018 - val_accuracy: 0.1820\n",
      "Epoch 4/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 2.2570 - accuracy: 0.1643\n",
      "Epoch 00004: val_loss improved from 2.20183 to 2.17304, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 2.2581 - accuracy: 0.1626 - val_loss: 2.1730 - val_accuracy: 0.1826\n",
      "Epoch 5/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 2.1882 - accuracy: 0.1762\n",
      "Epoch 00005: val_loss improved from 2.17304 to 2.09782, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.1829 - accuracy: 0.1790 - val_loss: 2.0978 - val_accuracy: 0.2232\n",
      "Epoch 6/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 2.1608 - accuracy: 0.1942\n",
      "Epoch 00006: val_loss improved from 2.09782 to 2.07199, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.1571 - accuracy: 0.1938 - val_loss: 2.0720 - val_accuracy: 0.2232\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 2.1255 - accuracy: 0.2179\n",
      "Epoch 00007: val_loss improved from 2.07199 to 2.03105, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.1255 - accuracy: 0.2179 - val_loss: 2.0311 - val_accuracy: 0.2433\n",
      "Epoch 8/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 2.0976 - accuracy: 0.2192\n",
      "Epoch 00008: val_loss improved from 2.03105 to 1.99402, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.0985 - accuracy: 0.2198 - val_loss: 1.9940 - val_accuracy: 0.2553\n",
      "Epoch 9/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 2.0725 - accuracy: 0.2300\n",
      "Epoch 00009: val_loss improved from 1.99402 to 1.98593, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 2.0722 - accuracy: 0.2286 - val_loss: 1.9859 - val_accuracy: 0.2627\n",
      "Epoch 10/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 2.0524 - accuracy: 0.2430\n",
      "Epoch 00010: val_loss improved from 1.98593 to 1.95763, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.0523 - accuracy: 0.2440 - val_loss: 1.9576 - val_accuracy: 0.2816\n",
      "Epoch 11/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 2.0206 - accuracy: 0.2503\n",
      "Epoch 00011: val_loss did not improve from 1.95763\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.0242 - accuracy: 0.2510 - val_loss: 1.9586 - val_accuracy: 0.2868\n",
      "Epoch 12/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 1.9920 - accuracy: 0.2654\n",
      "Epoch 00012: val_loss improved from 1.95763 to 1.89018, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.9929 - accuracy: 0.2657 - val_loss: 1.8902 - val_accuracy: 0.3034\n",
      "Epoch 13/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 1.9518 - accuracy: 0.2745\n",
      "Epoch 00013: val_loss improved from 1.89018 to 1.81085, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 1.9524 - accuracy: 0.2746 - val_loss: 1.8109 - val_accuracy: 0.3497\n",
      "Epoch 14/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 1.8942 - accuracy: 0.2946\n",
      "Epoch 00014: val_loss improved from 1.81085 to 1.70869, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.8907 - accuracy: 0.2952 - val_loss: 1.7087 - val_accuracy: 0.3646\n",
      "Epoch 15/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 1.8368 - accuracy: 0.3196\n",
      "Epoch 00015: val_loss improved from 1.70869 to 1.65190, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.8308 - accuracy: 0.3218 - val_loss: 1.6519 - val_accuracy: 0.4007\n",
      "Epoch 16/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 1.7781 - accuracy: 0.3432\n",
      "Epoch 00016: val_loss improved from 1.65190 to 1.63949, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.7771 - accuracy: 0.3435 - val_loss: 1.6395 - val_accuracy: 0.4144\n",
      "Epoch 17/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.7298 - accuracy: 0.3688\n",
      "Epoch 00017: val_loss improved from 1.63949 to 1.55086, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.7287 - accuracy: 0.3698 - val_loss: 1.5509 - val_accuracy: 0.4648\n",
      "Epoch 18/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.6946 - accuracy: 0.3822\n",
      "Epoch 00018: val_loss improved from 1.55086 to 1.51431, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.6944 - accuracy: 0.3822 - val_loss: 1.5143 - val_accuracy: 0.4568\n",
      "Epoch 19/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.6657 - accuracy: 0.3945\n",
      "Epoch 00019: val_loss improved from 1.51431 to 1.50834, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.6683 - accuracy: 0.3947 - val_loss: 1.5083 - val_accuracy: 0.4585\n",
      "Epoch 20/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.6186 - accuracy: 0.4112\n",
      "Epoch 00020: val_loss improved from 1.50834 to 1.49018, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.6203 - accuracy: 0.4106 - val_loss: 1.4902 - val_accuracy: 0.4642\n",
      "Epoch 21/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.6053 - accuracy: 0.4196\n",
      "Epoch 00021: val_loss improved from 1.49018 to 1.39325, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.6050 - accuracy: 0.4195 - val_loss: 1.3932 - val_accuracy: 0.5220\n",
      "Epoch 22/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 1.5354 - accuracy: 0.4504\n",
      "Epoch 00022: val_loss improved from 1.39325 to 1.38611, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.5314 - accuracy: 0.4515 - val_loss: 1.3861 - val_accuracy: 0.5283\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.5277 - accuracy: 0.4551\n",
      "Epoch 00023: val_loss improved from 1.38611 to 1.35275, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.5277 - accuracy: 0.4551 - val_loss: 1.3528 - val_accuracy: 0.5318\n",
      "Epoch 24/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 1.4888 - accuracy: 0.4593\n",
      "Epoch 00024: val_loss improved from 1.35275 to 1.30993, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.4834 - accuracy: 0.4624 - val_loss: 1.3099 - val_accuracy: 0.5541\n",
      "Epoch 25/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 1.4875 - accuracy: 0.4693\n",
      "Epoch 00025: val_loss improved from 1.30993 to 1.28629, saving model to saved_models\\audio_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 1s 4ms/step - loss: 1.4872 - accuracy: 0.4699 - val_loss: 1.2863 - val_accuracy: 0.5713\n",
      "Epoch 26/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 1.4452 - accuracy: 0.4880\n",
      "Epoch 00026: val_loss improved from 1.28629 to 1.26808, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.4469 - accuracy: 0.4880 - val_loss: 1.2681 - val_accuracy: 0.5850\n",
      "Epoch 27/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.4260 - accuracy: 0.4969\n",
      "Epoch 00027: val_loss improved from 1.26808 to 1.22917, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.4252 - accuracy: 0.4976 - val_loss: 1.2292 - val_accuracy: 0.6113\n",
      "Epoch 28/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.3999 - accuracy: 0.5026\n",
      "Epoch 00028: val_loss did not improve from 1.22917\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.4103 - accuracy: 0.5002 - val_loss: 1.2312 - val_accuracy: 0.6050\n",
      "Epoch 29/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.3802 - accuracy: 0.5098\n",
      "Epoch 00029: val_loss improved from 1.22917 to 1.22331, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3784 - accuracy: 0.5095 - val_loss: 1.2233 - val_accuracy: 0.6090\n",
      "Epoch 30/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 1.3580 - accuracy: 0.5305\n",
      "Epoch 00030: val_loss improved from 1.22331 to 1.18965, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3598 - accuracy: 0.5297 - val_loss: 1.1896 - val_accuracy: 0.6090\n",
      "Epoch 31/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 1.3385 - accuracy: 0.5379\n",
      "Epoch 00031: val_loss improved from 1.18965 to 1.17277, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3435 - accuracy: 0.5359 - val_loss: 1.1728 - val_accuracy: 0.6216\n",
      "Epoch 32/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.3119 - accuracy: 0.5465\n",
      "Epoch 00032: val_loss improved from 1.17277 to 1.15755, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.3134 - accuracy: 0.5459 - val_loss: 1.1575 - val_accuracy: 0.6405\n",
      "Epoch 33/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.3118 - accuracy: 0.5404\n",
      "Epoch 00033: val_loss improved from 1.15755 to 1.13123, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.3106 - accuracy: 0.5402 - val_loss: 1.1312 - val_accuracy: 0.6291\n",
      "Epoch 34/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.2806 - accuracy: 0.5603\n",
      "Epoch 00034: val_loss improved from 1.13123 to 1.11604, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2815 - accuracy: 0.5601 - val_loss: 1.1160 - val_accuracy: 0.6382\n",
      "Epoch 35/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.2874 - accuracy: 0.5615\n",
      "Epoch 00035: val_loss did not improve from 1.11604\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.2848 - accuracy: 0.5625 - val_loss: 1.1271 - val_accuracy: 0.6377\n",
      "Epoch 36/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.2670 - accuracy: 0.5686\n",
      "Epoch 00036: val_loss improved from 1.11604 to 1.09435, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.2692 - accuracy: 0.5708 - val_loss: 1.0943 - val_accuracy: 0.6463\n",
      "Epoch 37/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.2717 - accuracy: 0.5732\n",
      "Epoch 00037: val_loss did not improve from 1.09435\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.2798 - accuracy: 0.5695 - val_loss: 1.1073 - val_accuracy: 0.6417\n",
      "Epoch 38/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 1.2408 - accuracy: 0.5731\n",
      "Epoch 00038: val_loss improved from 1.09435 to 1.07587, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2479 - accuracy: 0.5715 - val_loss: 1.0759 - val_accuracy: 0.6525\n",
      "Epoch 39/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 1.2370 - accuracy: 0.5783\n",
      "Epoch 00039: val_loss improved from 1.07587 to 1.06482, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2349 - accuracy: 0.5792 - val_loss: 1.0648 - val_accuracy: 0.6508\n",
      "Epoch 40/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.2202 - accuracy: 0.5800\n",
      "Epoch 00040: val_loss improved from 1.06482 to 1.03183, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.2165 - accuracy: 0.5817 - val_loss: 1.0318 - val_accuracy: 0.6617\n",
      "Epoch 41/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.2257 - accuracy: 0.5850\n",
      "Epoch 00041: val_loss did not improve from 1.03183\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.2218 - accuracy: 0.5870 - val_loss: 1.0514 - val_accuracy: 0.6674\n",
      "Epoch 42/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 1.2239 - accuracy: 0.5853\n",
      "Epoch 00042: val_loss improved from 1.03183 to 1.02012, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 1.2209 - accuracy: 0.5864 - val_loss: 1.0201 - val_accuracy: 0.6709\n",
      "Epoch 43/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.1839 - accuracy: 0.5988\n",
      "Epoch 00043: val_loss improved from 1.02012 to 1.00053, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1875 - accuracy: 0.5979 - val_loss: 1.0005 - val_accuracy: 0.6714\n",
      "Epoch 44/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.1880 - accuracy: 0.5949\n",
      "Epoch 00044: val_loss did not improve from 1.00053\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.1873 - accuracy: 0.5950 - val_loss: 1.0040 - val_accuracy: 0.6749\n",
      "Epoch 45/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.1838 - accuracy: 0.5952\n",
      "Epoch 00045: val_loss did not improve from 1.00053\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.1855 - accuracy: 0.5943 - val_loss: 1.0073 - val_accuracy: 0.6760\n",
      "Epoch 46/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 1.1651 - accuracy: 0.5907\n",
      "Epoch 00046: val_loss improved from 1.00053 to 0.94929, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1584 - accuracy: 0.5926 - val_loss: 0.9493 - val_accuracy: 0.6863\n",
      "Epoch 47/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 1.1579 - accuracy: 0.6143\n",
      "Epoch 00047: val_loss did not improve from 0.94929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.1590 - accuracy: 0.6146 - val_loss: 0.9716 - val_accuracy: 0.6714\n",
      "Epoch 48/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 1.1514 - accuracy: 0.6092\n",
      "Epoch 00048: val_loss did not improve from 0.94929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.1482 - accuracy: 0.6109 - val_loss: 0.9624 - val_accuracy: 0.6823\n",
      "Epoch 49/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 1.1288 - accuracy: 0.6172\n",
      "Epoch 00049: val_loss improved from 0.94929 to 0.94715, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1270 - accuracy: 0.6170 - val_loss: 0.9472 - val_accuracy: 0.6823\n",
      "Epoch 50/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.1347 - accuracy: 0.6140\n",
      "Epoch 00050: val_loss improved from 0.94715 to 0.92250, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1313 - accuracy: 0.6163 - val_loss: 0.9225 - val_accuracy: 0.6932\n",
      "Epoch 51/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.1553 - accuracy: 0.6092\n",
      "Epoch 00051: val_loss did not improve from 0.92250\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1553 - accuracy: 0.6093 - val_loss: 0.9248 - val_accuracy: 0.6961\n",
      "Epoch 52/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.1115 - accuracy: 0.6182\n",
      "Epoch 00052: val_loss improved from 0.92250 to 0.91882, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1130 - accuracy: 0.6185 - val_loss: 0.9188 - val_accuracy: 0.6880\n",
      "Epoch 53/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 1.1142 - accuracy: 0.6242\n",
      "Epoch 00053: val_loss did not improve from 0.91882\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.1172 - accuracy: 0.6208 - val_loss: 0.9362 - val_accuracy: 0.6978\n",
      "Epoch 54/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0869 - accuracy: 0.6284\n",
      "Epoch 00054: val_loss improved from 0.91882 to 0.90470, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0873 - accuracy: 0.6282 - val_loss: 0.9047 - val_accuracy: 0.6898\n",
      "Epoch 55/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 1.1104 - accuracy: 0.6255\n",
      "Epoch 00055: val_loss did not improve from 0.90470\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.1128 - accuracy: 0.6255 - val_loss: 0.9637 - val_accuracy: 0.6926\n",
      "Epoch 56/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.0852 - accuracy: 0.6350\n",
      "Epoch 00056: val_loss did not improve from 0.90470\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0903 - accuracy: 0.6336 - val_loss: 0.9253 - val_accuracy: 0.7012\n",
      "Epoch 57/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0673 - accuracy: 0.6377\n",
      "Epoch 00057: val_loss improved from 0.90470 to 0.89816, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0721 - accuracy: 0.6354 - val_loss: 0.8982 - val_accuracy: 0.7029\n",
      "Epoch 58/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.0977 - accuracy: 0.6385\n",
      "Epoch 00058: val_loss improved from 0.89816 to 0.88712, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0973 - accuracy: 0.6382 - val_loss: 0.8871 - val_accuracy: 0.7195\n",
      "Epoch 59/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 1.0654 - accuracy: 0.6433\n",
      "Epoch 00059: val_loss did not improve from 0.88712\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0642 - accuracy: 0.6429 - val_loss: 0.8905 - val_accuracy: 0.7115\n",
      "Epoch 60/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.0893 - accuracy: 0.6330\n",
      "Epoch 00060: val_loss did not improve from 0.88712\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0893 - accuracy: 0.6319 - val_loss: 0.9280 - val_accuracy: 0.6926\n",
      "Epoch 61/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0687 - accuracy: 0.6451\n",
      "Epoch 00061: val_loss did not improve from 0.88712\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0708 - accuracy: 0.6418 - val_loss: 0.8886 - val_accuracy: 0.7127\n",
      "Epoch 62/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0651 - accuracy: 0.6418\n",
      "Epoch 00062: val_loss did not improve from 0.88712\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0601 - accuracy: 0.6437 - val_loss: 0.9124 - val_accuracy: 0.7075\n",
      "Epoch 63/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.0705 - accuracy: 0.6372\n",
      "Epoch 00063: val_loss improved from 0.88712 to 0.88495, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0739 - accuracy: 0.6358 - val_loss: 0.8850 - val_accuracy: 0.7167\n",
      "Epoch 64/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 1.0754 - accuracy: 0.6403\n",
      "Epoch 00064: val_loss did not improve from 0.88495\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0739 - accuracy: 0.6397 - val_loss: 0.8986 - val_accuracy: 0.7081\n",
      "Epoch 65/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 1.0388 - accuracy: 0.6518\n",
      "Epoch 00065: val_loss improved from 0.88495 to 0.86600, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0452 - accuracy: 0.6482 - val_loss: 0.8660 - val_accuracy: 0.7218\n",
      "Epoch 66/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 1.0406 - accuracy: 0.6420\n",
      "Epoch 00066: val_loss improved from 0.86600 to 0.85547, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.0407 - accuracy: 0.6431 - val_loss: 0.8555 - val_accuracy: 0.7218\n",
      "Epoch 67/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 1.0596 - accuracy: 0.6430\n",
      "Epoch 00067: val_loss did not improve from 0.85547\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0575 - accuracy: 0.6438 - val_loss: 0.8811 - val_accuracy: 0.7092\n",
      "Epoch 68/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 1.0498 - accuracy: 0.6437\n",
      "Epoch 00068: val_loss did not improve from 0.85547\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0495 - accuracy: 0.6438 - val_loss: 0.8680 - val_accuracy: 0.7230\n",
      "Epoch 69/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.0269 - accuracy: 0.6562\n",
      "Epoch 00069: val_loss improved from 0.85547 to 0.83952, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0334 - accuracy: 0.6544 - val_loss: 0.8395 - val_accuracy: 0.7270\n",
      "Epoch 70/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 1.0640 - accuracy: 0.6445\n",
      "Epoch 00070: val_loss did not improve from 0.83952\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0652 - accuracy: 0.6428 - val_loss: 0.8678 - val_accuracy: 0.7230\n",
      "Epoch 71/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 1.0283 - accuracy: 0.6531\n",
      "Epoch 00071: val_loss improved from 0.83952 to 0.82869, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0296 - accuracy: 0.6520 - val_loss: 0.8287 - val_accuracy: 0.7270\n",
      "Epoch 72/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 1.0269 - accuracy: 0.6567\n",
      "Epoch 00072: val_loss did not improve from 0.82869\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0280 - accuracy: 0.6565 - val_loss: 0.8913 - val_accuracy: 0.7138\n",
      "Epoch 73/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.0175 - accuracy: 0.6623\n",
      "Epoch 00073: val_loss did not improve from 0.82869\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0188 - accuracy: 0.6620 - val_loss: 0.8341 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 1.0279 - accuracy: 0.6573\n",
      "Epoch 00074: val_loss did not improve from 0.82869\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0340 - accuracy: 0.6557 - val_loss: 0.8324 - val_accuracy: 0.7424\n",
      "Epoch 75/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 1.0218 - accuracy: 0.6606\n",
      "Epoch 00075: val_loss did not improve from 0.82869\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0229 - accuracy: 0.6584 - val_loss: 0.8452 - val_accuracy: 0.7350\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.0106 - accuracy: 0.6623\n",
      "Epoch 00076: val_loss did not improve from 0.82869\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0106 - accuracy: 0.6623 - val_loss: 0.8317 - val_accuracy: 0.7350\n",
      "Epoch 77/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0050 - accuracy: 0.6630\n",
      "Epoch 00077: val_loss did not improve from 0.82869\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0044 - accuracy: 0.6630 - val_loss: 0.8550 - val_accuracy: 0.7293\n",
      "Epoch 78/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 1.0145 - accuracy: 0.6574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00078: val_loss did not improve from 0.82869\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0148 - accuracy: 0.6567 - val_loss: 0.8591 - val_accuracy: 0.7338\n",
      "Epoch 79/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 1.0018 - accuracy: 0.6669\n",
      "Epoch 00079: val_loss did not improve from 0.82869\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0033 - accuracy: 0.6667 - val_loss: 0.8608 - val_accuracy: 0.7275\n",
      "Epoch 80/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0032 - accuracy: 0.6639\n",
      "Epoch 00080: val_loss improved from 0.82869 to 0.81622, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.0013 - accuracy: 0.6628 - val_loss: 0.8162 - val_accuracy: 0.7401\n",
      "Epoch 81/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 1.0011 - accuracy: 0.6630\n",
      "Epoch 00081: val_loss did not improve from 0.81622\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9996 - accuracy: 0.6631 - val_loss: 0.8415 - val_accuracy: 0.7344\n",
      "Epoch 82/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9825 - accuracy: 0.6700\n",
      "Epoch 00082: val_loss did not improve from 0.81622\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9825 - accuracy: 0.6700 - val_loss: 0.8194 - val_accuracy: 0.7533\n",
      "Epoch 83/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 0.9803 - accuracy: 0.6761\n",
      "Epoch 00083: val_loss improved from 0.81622 to 0.81053, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9827 - accuracy: 0.6757 - val_loss: 0.8105 - val_accuracy: 0.7550\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9970 - accuracy: 0.6634\n",
      "Epoch 00084: val_loss did not improve from 0.81053\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9970 - accuracy: 0.6634 - val_loss: 0.8190 - val_accuracy: 0.7499\n",
      "Epoch 85/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 0.9626 - accuracy: 0.6778\n",
      "Epoch 00085: val_loss did not improve from 0.81053\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9630 - accuracy: 0.6747 - val_loss: 0.8168 - val_accuracy: 0.7436\n",
      "Epoch 86/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.9949 - accuracy: 0.6711\n",
      "Epoch 00086: val_loss did not improve from 0.81053\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9955 - accuracy: 0.6720 - val_loss: 0.8313 - val_accuracy: 0.7310\n",
      "Epoch 87/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 1.0081 - accuracy: 0.6691\n",
      "Epoch 00087: val_loss did not improve from 0.81053\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0001 - accuracy: 0.6713 - val_loss: 0.8206 - val_accuracy: 0.7430\n",
      "Epoch 88/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 0.9800 - accuracy: 0.6683\n",
      "Epoch 00088: val_loss did not improve from 0.81053\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9862 - accuracy: 0.6684 - val_loss: 0.8138 - val_accuracy: 0.7470\n",
      "Epoch 89/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.9491 - accuracy: 0.6821\n",
      "Epoch 00089: val_loss improved from 0.81053 to 0.78542, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9530 - accuracy: 0.6809 - val_loss: 0.7854 - val_accuracy: 0.7493\n",
      "Epoch 90/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 0.9789 - accuracy: 0.6711\n",
      "Epoch 00090: val_loss did not improve from 0.78542\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9839 - accuracy: 0.6700 - val_loss: 0.8191 - val_accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 0.9767 - accuracy: 0.6749\n",
      "Epoch 00091: val_loss did not improve from 0.78542\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9733 - accuracy: 0.6744 - val_loss: 0.8071 - val_accuracy: 0.7407\n",
      "Epoch 92/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.9929 - accuracy: 0.6691\n",
      "Epoch 00092: val_loss did not improve from 0.78542\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9898 - accuracy: 0.6693 - val_loss: 0.8264 - val_accuracy: 0.7378\n",
      "Epoch 93/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 0.9972 - accuracy: 0.6640\n",
      "Epoch 00093: val_loss did not improve from 0.78542\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9972 - accuracy: 0.6654 - val_loss: 0.8138 - val_accuracy: 0.7418\n",
      "Epoch 94/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 1.0072 - accuracy: 0.6701 ETA: 0s - loss: 1.0119 - accuracy: \n",
      "Epoch 00094: val_loss did not improve from 0.78542\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0046 - accuracy: 0.6703 - val_loss: 0.7970 - val_accuracy: 0.7441\n",
      "Epoch 95/100\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 0.9861 - accuracy: 0.6775\n",
      "Epoch 00095: val_loss did not improve from 0.78542\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9914 - accuracy: 0.6740 - val_loss: 0.8140 - val_accuracy: 0.7436\n",
      "Epoch 96/100\n",
      "198/219 [==========================>...] - ETA: 0s - loss: 0.9598 - accuracy: 0.6758\n",
      "Epoch 00096: val_loss improved from 0.78542 to 0.78194, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9667 - accuracy: 0.6723 - val_loss: 0.7819 - val_accuracy: 0.7550\n",
      "Epoch 97/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9797 - accuracy: 0.6740\n",
      "Epoch 00097: val_loss improved from 0.78194 to 0.77915, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9789 - accuracy: 0.6737 - val_loss: 0.7791 - val_accuracy: 0.7510\n",
      "Epoch 98/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9622 - accuracy: 0.6781\n",
      "Epoch 00098: val_loss improved from 0.77915 to 0.77684, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9595 - accuracy: 0.6792 - val_loss: 0.7768 - val_accuracy: 0.7544\n",
      "Epoch 99/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.9483 - accuracy: 0.6831\n",
      "Epoch 00099: val_loss did not improve from 0.77684\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9474 - accuracy: 0.6838 - val_loss: 0.7870 - val_accuracy: 0.7556\n",
      "Epoch 100/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.9646 - accuracy: 0.6799\n",
      "Epoch 00100: val_loss did not improve from 0.77684\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9658 - accuracy: 0.6786 - val_loss: 0.7968 - val_accuracy: 0.7516\n",
      "Training completed in time:  0:01:10.680855\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cd6681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7515740990638733\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
